<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />
  <meta name="mobile-web-app-capable" content="yes" />
  <title>Voice Assistant</title>
  <link rel="preconnect" href="https://fonts.googleapis.com" />
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
  <link href="https://fonts.googleapis.com/css2?family=DM+Sans:ital,opsz,wght@0,9..40,300;0,9..40,400;0,9..40,500;1,9..40,300&display=swap" rel="stylesheet" />
  <style>
    *, *::before, *::after { margin: 0; padding: 0; box-sizing: border-box; }

    :root {
      --bg: #0a0a0c;
      --surface: #141418;
      --surface-hover: #1c1c22;
      --border: #2a2a33;
      --text: #e8e6f0;
      --text-dim: #8b879e;
      --accent: #6e5eff;
      --accent-glow: rgba(110, 94, 255, 0.35);
      --recording: #ff4d6a;
      --recording-glow: rgba(255, 77, 106, 0.4);
      --user-bubble: #1e1c2e;
      --ai-bubble: #17171f;
      --safe-bottom: env(safe-area-inset-bottom, 0px);
    }

    html, body {
      height: 100%;
      background: var(--bg);
      color: var(--text);
      font-family: 'DM Sans', -apple-system, sans-serif;
      font-size: 15px;
      line-height: 1.55;
      overflow: hidden;
      -webkit-font-smoothing: antialiased;
      -webkit-tap-highlight-color: transparent;
    }

    #app {
      display: flex;
      flex-direction: column;
      height: 100dvh;
      max-width: 520px;
      margin: 0 auto;
    }

    /* ── Header ── */
    header {
      flex-shrink: 0;
      padding: 16px 20px 12px;
      border-bottom: 1px solid var(--border);
      display: flex;
      align-items: center;
      gap: 12px;
      backdrop-filter: blur(20px);
      -webkit-backdrop-filter: blur(20px);
      background: rgba(10, 10, 12, 0.85);
      z-index: 10;
    }

    .logo-mark {
      width: 34px;
      height: 34px;
      border-radius: 10px;
      background: linear-gradient(135deg, var(--accent), #9b6eff);
      display: flex;
      align-items: center;
      justify-content: center;
      flex-shrink: 0;
    }

    .logo-mark svg { width: 18px; height: 18px; fill: white; }

    header h1 {
      font-size: 17px;
      font-weight: 500;
      letter-spacing: -0.02em;
    }

    header .subtitle {
      font-size: 12px;
      color: var(--text-dim);
      font-weight: 300;
    }

    /* ── Chat area ── */
    #chat {
      flex: 1;
      overflow-y: auto;
      padding: 20px 16px;
      display: flex;
      flex-direction: column;
      gap: 12px;
      -webkit-overflow-scrolling: touch;
      scroll-behavior: smooth;
    }

    #chat::-webkit-scrollbar { width: 0; }

    .msg {
      max-width: 85%;
      padding: 12px 16px;
      border-radius: 18px;
      font-size: 14.5px;
      line-height: 1.55;
      animation: msgIn 0.3s cubic-bezier(0.22, 1, 0.36, 1);
      word-wrap: break-word;
    }

    .msg.user {
      align-self: flex-end;
      background: var(--user-bubble);
      border: 1px solid var(--border);
      border-bottom-right-radius: 6px;
      color: var(--text);
    }

    .msg.assistant {
      align-self: flex-start;
      background: var(--ai-bubble);
      border: 1px solid rgba(110, 94, 255, 0.12);
      border-bottom-left-radius: 6px;
      color: var(--text);
    }

    .msg.system {
      align-self: center;
      background: transparent;
      color: var(--text-dim);
      font-size: 13px;
      font-style: italic;
      padding: 6px 12px;
    }

    @keyframes msgIn {
      from { opacity: 0; transform: translateY(8px) scale(0.97); }
      to { opacity: 1; transform: translateY(0) scale(1); }
    }

    /* ── Thinking indicator ── */
    .thinking {
      align-self: flex-start;
      display: flex;
      gap: 5px;
      padding: 14px 20px;
      background: var(--ai-bubble);
      border: 1px solid rgba(110, 94, 255, 0.12);
      border-radius: 18px;
      border-bottom-left-radius: 6px;
      animation: msgIn 0.3s cubic-bezier(0.22, 1, 0.36, 1);
    }

    .thinking span {
      width: 7px;
      height: 7px;
      border-radius: 50%;
      background: var(--accent);
      opacity: 0.4;
      animation: dot 1.2s ease-in-out infinite;
    }

    .thinking span:nth-child(2) { animation-delay: 0.15s; }
    .thinking span:nth-child(3) { animation-delay: 0.3s; }

    @keyframes dot {
      0%, 60%, 100% { opacity: 0.25; transform: scale(0.85); }
      30% { opacity: 0.9; transform: scale(1.1); }
    }

    /* ── Bottom controls ── */
    #controls {
      flex-shrink: 0;
      padding: 16px 20px calc(16px + var(--safe-bottom));
      border-top: 1px solid var(--border);
      display: flex;
      flex-direction: column;
      align-items: center;
      gap: 10px;
      background: rgba(10, 10, 12, 0.92);
      backdrop-filter: blur(20px);
      -webkit-backdrop-filter: blur(20px);
    }

    #status {
      font-size: 13px;
      color: var(--text-dim);
      font-weight: 300;
      min-height: 20px;
      text-align: center;
      transition: color 0.2s;
    }

    #status.recording { color: var(--recording); }
    #status.processing { color: var(--accent); }
    #status.speaking { color: #5ee6a0; }

    #mic-btn {
      width: 72px;
      height: 72px;
      border-radius: 50%;
      border: 2px solid var(--border);
      background: var(--surface);
      color: var(--text);
      cursor: pointer;
      display: flex;
      align-items: center;
      justify-content: center;
      transition: all 0.25s cubic-bezier(0.22, 1, 0.36, 1);
      position: relative;
      -webkit-user-select: none;
      user-select: none;
      touch-action: manipulation;
    }

    #mic-btn:active { transform: scale(0.95); }

    #mic-btn svg {
      width: 26px;
      height: 26px;
      transition: all 0.25s;
      position: relative;
      z-index: 1;
    }

    #mic-btn.recording {
      border-color: var(--recording);
      background: rgba(255, 77, 106, 0.12);
      box-shadow: 0 0 0 6px var(--recording-glow), 0 0 30px var(--recording-glow);
    }

    #mic-btn.recording svg { fill: var(--recording); }

    #mic-btn.disabled {
      opacity: 0.4;
      pointer-events: none;
    }

    /* Pulse ring when recording */
    #mic-btn.recording::after {
      content: '';
      position: absolute;
      inset: -8px;
      border-radius: 50%;
      border: 2px solid var(--recording);
      opacity: 0;
      animation: pulse-ring 1.8s cubic-bezier(0.22, 1, 0.36, 1) infinite;
    }

    @keyframes pulse-ring {
      0% { transform: scale(0.9); opacity: 0.6; }
      100% { transform: scale(1.3); opacity: 0; }
    }

    /* ── Welcome state ── */
    .welcome {
      flex: 1;
      display: flex;
      flex-direction: column;
      align-items: center;
      justify-content: center;
      text-align: center;
      padding: 40px 30px;
      gap: 16px;
    }

    .welcome .icon-wrap {
      width: 72px;
      height: 72px;
      border-radius: 22px;
      background: linear-gradient(135deg, rgba(110, 94, 255, 0.15), rgba(155, 110, 255, 0.08));
      border: 1px solid rgba(110, 94, 255, 0.2);
      display: flex;
      align-items: center;
      justify-content: center;
      margin-bottom: 4px;
    }

    .welcome .icon-wrap svg {
      width: 32px;
      height: 32px;
      fill: var(--accent);
      opacity: 0.85;
    }

    .welcome h2 {
      font-size: 20px;
      font-weight: 400;
      letter-spacing: -0.02em;
    }

    .welcome p {
      color: var(--text-dim);
      font-size: 14px;
      font-weight: 300;
      max-width: 260px;
      line-height: 1.6;
    }

    /* Audio visualizer bar */
    #visualizer {
      display: flex;
      gap: 3px;
      align-items: center;
      height: 24px;
      opacity: 0;
      transition: opacity 0.3s;
    }

    #visualizer.active { opacity: 1; }

    #visualizer .bar {
      width: 3px;
      height: 6px;
      background: var(--recording);
      border-radius: 2px;
      transition: height 0.08s ease;
    }
  </style>
</head>
<body>
  <div id="app">
    <header>
      <div class="logo-mark">
        <svg viewBox="0 0 24 24"><path d="M12 1a3 3 0 0 0-3 3v8a3 3 0 0 0 6 0V4a3 3 0 0 0-3-3z"/><path d="M19 10v2a7 7 0 0 1-14 0v-2"/><line x1="12" y1="19" x2="12" y2="23" stroke="white" stroke-width="2"/><line x1="8" y1="23" x2="16" y2="23" stroke="white" stroke-width="2"/></svg>
      </div>
      <div>
        <h1>Voice Assistant</h1>
        <div class="subtitle">Powered by Claude &amp; ElevenLabs</div>
      </div>
    </header>

    <div id="chat">
      <div class="welcome" id="welcome">
        <div class="icon-wrap">
          <svg viewBox="0 0 24 24"><path d="M12 1a3 3 0 0 0-3 3v8a3 3 0 0 0 6 0V4a3 3 0 0 0-3-3z"/><path d="M19 10v2a7 7 0 0 1-14 0v-2" fill="none" stroke="currentColor" stroke-width="2"/><line x1="12" y1="19" x2="12" y2="23" stroke="currentColor" stroke-width="2"/></svg>
        </div>
        <h2>Hey there</h2>
        <p>Tap the mic button to start speaking. Tap again when you're done. I'll listen, think, and respond.</p>
      </div>
    </div>

    <div id="controls">
      <div id="visualizer">
        <!-- bars injected by JS -->
      </div>
      <button id="mic-btn" aria-label="Toggle recording">
        <svg id="mic-icon" viewBox="0 0 24 24" fill="currentColor">
          <path d="M12 1a3 3 0 0 0-3 3v8a3 3 0 0 0 6 0V4a3 3 0 0 0-3-3z"/>
          <path d="M19 10v2a7 7 0 0 1-14 0v-2" fill="none" stroke="currentColor" stroke-width="2"/>
          <line x1="12" y1="19" x2="12" y2="23" stroke="currentColor" stroke-width="2"/>
          <line x1="8" y1="23" x2="16" y2="23" stroke="currentColor" stroke-width="2"/>
        </svg>
      </button>
      <div id="status">Tap to speak</div>
    </div>
  </div>

  <script>
    const chatEl = document.getElementById("chat");
    const welcomeEl = document.getElementById("welcome");
    const micBtn = document.getElementById("mic-btn");
    const statusEl = document.getElementById("status");
    const visualizerEl = document.getElementById("visualizer");

    // State
    let isRecording = false;
    let isProcessing = false;
    let mediaRecorder = null;
    let audioChunks = [];
    let audioStream = null;
    let analyser = null;
    let animFrameId = null;
    let conversationHistory = [];
    let currentAudio = null;

    // Create visualizer bars
    const BAR_COUNT = 20;
    for (let i = 0; i < BAR_COUNT; i++) {
      const bar = document.createElement("div");
      bar.className = "bar";
      visualizerEl.appendChild(bar);
    }
    const bars = visualizerEl.querySelectorAll(".bar");

    // ── Mic button handler ──
    micBtn.addEventListener("click", async () => {
      if (isProcessing) return;

      // Stop any currently playing audio
      if (currentAudio) {
        currentAudio.pause();
        currentAudio.currentTime = 0;
        currentAudio = null;
      }

      if (!isRecording) {
        await startRecording();
      } else {
        stopRecording();
      }
    });

    async function startRecording() {
      try {
        // iOS-compatible audio constraints
        const constraints = {
          audio: {
            echoCancellation: true,
            noiseSuppression: true,
            sampleRate: 44100,
          }
        };

        audioStream = await navigator.mediaDevices.getUserMedia(constraints);

        // Set up analyser for visualizer
        const audioCtx = new (window.AudioContext || window.webkitAudioContext)();
        if (audioCtx.state === "suspended") await audioCtx.resume();
        const source = audioCtx.createMediaStreamSource(audioStream);
        analyser = audioCtx.createAnalyser();
        analyser.fftSize = 64;
        source.connect(analyser);

        // Determine best supported mime type
        let mimeType = "audio/webm;codecs=opus";
        if (!MediaRecorder.isTypeSupported(mimeType)) {
          mimeType = "audio/webm";
        }
        if (!MediaRecorder.isTypeSupported(mimeType)) {
          mimeType = "audio/mp4";
        }
        if (!MediaRecorder.isTypeSupported(mimeType)) {
          mimeType = ""; // let browser pick
        }

        const options = mimeType ? { mimeType } : {};
        mediaRecorder = new MediaRecorder(audioStream, options);
        audioChunks = [];

        mediaRecorder.ondataavailable = (e) => {
          if (e.data.size > 0) audioChunks.push(e.data);
        };

        mediaRecorder.onstop = () => {
          const actualMime = mediaRecorder.mimeType || mimeType || "audio/webm";
          const blob = new Blob(audioChunks, { type: actualMime });
          handleAudioBlob(blob, actualMime);
        };

        mediaRecorder.start(250); // collect in 250ms chunks
        isRecording = true;
        micBtn.classList.add("recording");
        statusEl.textContent = "Listening…";
        statusEl.className = "recording";
        visualizerEl.classList.add("active");
        animateVisualizer();
      } catch (err) {
        console.error("Mic access failed:", err);
        statusEl.textContent = "Microphone access denied";
        statusEl.className = "";
      }
    }

    function stopRecording() {
      if (mediaRecorder && mediaRecorder.state !== "inactive") {
        mediaRecorder.stop();
      }
      if (audioStream) {
        audioStream.getTracks().forEach((t) => t.stop());
        audioStream = null;
      }
      isRecording = false;
      micBtn.classList.remove("recording");
      visualizerEl.classList.remove("active");
      if (animFrameId) cancelAnimationFrame(animFrameId);
    }

    function animateVisualizer() {
      if (!analyser || !isRecording) return;
      const data = new Uint8Array(analyser.frequencyBinCount);
      analyser.getByteFrequencyData(data);

      bars.forEach((bar, i) => {
        const val = data[i] || 0;
        const h = Math.max(4, (val / 255) * 28);
        bar.style.height = h + "px";
      });

      animFrameId = requestAnimationFrame(animateVisualizer);
    }

    // ── Process recorded audio ──
    async function handleAudioBlob(blob, mimeType) {
      if (blob.size < 1000) {
        statusEl.textContent = "Tap to speak";
        statusEl.className = "";
        return;
      }

      isProcessing = true;
      micBtn.classList.add("disabled");
      statusEl.textContent = "Transcribing…";
      statusEl.className = "processing";

      // Remove welcome message on first interaction
      if (welcomeEl) welcomeEl.remove();

      try {
        // 1. Transcribe audio via Claude
        const formData = new FormData();
        formData.append("audio", blob, "recording." + (mimeType.includes("mp4") ? "mp4" : "webm"));

        const transcribeRes = await fetch("/api/transcribe", {
          method: "POST",
          body: formData,
        });

        if (!transcribeRes.ok) throw new Error("Transcription failed");
        const { text: userText } = await transcribeRes.json();

        if (!userText || userText === "[inaudible]") {
          statusEl.textContent = "Couldn't hear that. Try again.";
          statusEl.className = "";
          isProcessing = false;
          micBtn.classList.remove("disabled");
          return;
        }

        addMessage("user", userText);

        // 2. Get chat response from Claude
        statusEl.textContent = "Thinking…";
        showThinking();

        const chatRes = await fetch("/api/chat", {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({
            message: userText,
            history: conversationHistory,
          }),
        });

        if (!chatRes.ok) throw new Error("Chat failed");
        const { reply } = await chatRes.json();

        removeThinking();
        addMessage("assistant", reply);

        // Update conversation history
        conversationHistory.push({ role: "user", content: userText });
        conversationHistory.push({ role: "assistant", content: reply });

        // Keep history manageable (last 10 exchanges)
        if (conversationHistory.length > 20) {
          conversationHistory = conversationHistory.slice(-20);
        }

        // 3. Convert response to speech via ElevenLabs
        statusEl.textContent = "Speaking…";
        statusEl.className = "speaking";

        const speakRes = await fetch("/api/speak", {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({ text: reply }),
        });

        if (speakRes.ok) {
          const audioBlob = await speakRes.blob();
          const audioUrl = URL.createObjectURL(audioBlob);
          currentAudio = new Audio(audioUrl);
          currentAudio.onended = () => {
            statusEl.textContent = "Tap to speak";
            statusEl.className = "";
            currentAudio = null;
          };
          currentAudio.onerror = () => {
            statusEl.textContent = "Tap to speak";
            statusEl.className = "";
            currentAudio = null;
          };
          await currentAudio.play();
        } else {
          statusEl.textContent = "Tap to speak";
          statusEl.className = "";
        }
      } catch (err) {
        console.error("Pipeline error:", err);
        removeThinking();
        addMessage("system", "Something went wrong. Please try again.");
        statusEl.textContent = "Tap to speak";
        statusEl.className = "";
      } finally {
        isProcessing = false;
        micBtn.classList.remove("disabled");
      }
    }

    // ── UI Helpers ──
    function addMessage(role, text) {
      const div = document.createElement("div");
      div.className = `msg ${role}`;
      div.textContent = text;
      chatEl.appendChild(div);
      chatEl.scrollTop = chatEl.scrollHeight;
    }

    function showThinking() {
      const div = document.createElement("div");
      div.className = "thinking";
      div.id = "thinking-indicator";
      div.innerHTML = "<span></span><span></span><span></span>";
      chatEl.appendChild(div);
      chatEl.scrollTop = chatEl.scrollHeight;
    }

    function removeThinking() {
      const el = document.getElementById("thinking-indicator");
      if (el) el.remove();
    }
  </script>
</body>
</html>
